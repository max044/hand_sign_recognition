{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(static_image_mode=True, max_num_hands=1)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "\n",
    "def crop_img(img):\n",
    "    cropped_image = img\n",
    "    h, w, c = img.shape\n",
    "    if h < w:\n",
    "        wcenter = w/2\n",
    "        wmin = int(wcenter-h/2)\n",
    "        wmax = int(wcenter+h/2)\n",
    "        cropped_image = img[0:h, wmin:wmax]\n",
    "    else:\n",
    "        hcenter = h/2\n",
    "        hmin = int(hcenter-w/2)\n",
    "        hmax = int(hcenter+w/2)\n",
    "        cropped_image = img[hmin:hmax, 0:w]\n",
    "\n",
    "    imgRGB = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handlms in results.multi_hand_landmarks:\n",
    "            # z = max([lm.z for lm in handlms.landmark])\n",
    "            h, w, c = cropped_image.shape\n",
    "\n",
    "            xmax = max([int(lm.x*w) for lm in handlms.landmark])\n",
    "            xmax = w if xmax > w else xmax\n",
    "\n",
    "            xmin = min([int(lm.x*w) for lm in handlms.landmark])\n",
    "            xmin = 0 if xmin < 0 else xmin\n",
    "\n",
    "            ymax = max([int(lm.y*h) for lm in handlms.landmark])\n",
    "            ymax = h if ymax > h else ymax\n",
    "\n",
    "            ymin = min([int(lm.y*h) for lm in handlms.landmark])\n",
    "            ymin = 0 if ymin < 0 else ymin\n",
    "\n",
    "            xsize = int(xmax - xmin)\n",
    "            ysize = int(ymax - ymin)\n",
    "            \n",
    "            cv2.circle(cropped_image, (int((xmin+xmax)/2), int((ymin+ymax)/2)), max(int((xsize/2)+60), int((ysize/2)+60)), color, thickness)\n",
    "            \n",
    "            r = max(int((xsize/2)+60), int((ysize/2)+60))\n",
    "            xmin = int((xmin+xmax)/2 - r)\n",
    "            xmax = int((xmin+xmax)/2 + r)\n",
    "\n",
    "            if xmax > w:\n",
    "                xmax = w\n",
    "                xmin = int((xmin+xmax)/2 - r)\n",
    "\n",
    "            if xmin < 0:\n",
    "                xmin = 0\n",
    "                xmax = int((xmin+xmax)/2 + r)\n",
    "\n",
    "            ymin = int((ymin+ymax)/2 - r)\n",
    "            ymax = int((ymin+ymax)/2 + r)\n",
    "\n",
    "            if ymax > h:\n",
    "                ymax = h\n",
    "                ymin = int((ymin+ymax)/2 - r)\n",
    "\n",
    "            if ymin < 0:\n",
    "                ymin = 0\n",
    "                ymax = int((ymin+ymax)/2 + r)\n",
    "\n",
    "            \n",
    "            cropped_image = cropped_image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "            # for id, lm in enumerate(handlms.landmark):\n",
    "                #     cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                #     cropped_image = cv2.circle(cropped_image, (cx, cy), 25, color, thickness)\n",
    "                    \n",
    "                # mpDraw.draw_landmarks(cropped_image, handlms, mpHands.HAND_CONNECTIONS)\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [44], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m success, img \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m (success):\n\u001b[0;32m----> 9\u001b[0m     cropped_image \u001b[39m=\u001b[39m crop_img(img)\n\u001b[1;32m     11\u001b[0m     cTime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m     fps \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(cTime \u001b[39m-\u001b[39m pTime)\n",
      "Cell \u001b[0;32mIn [43], line 22\u001b[0m, in \u001b[0;36mcrop_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     19\u001b[0m     cropped_image \u001b[39m=\u001b[39m img[hmin:hmax, \u001b[39m0\u001b[39m:w]\n\u001b[1;32m     21\u001b[0m imgRGB \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(cropped_image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 22\u001b[0m results \u001b[39m=\u001b[39m hands\u001b[39m.\u001b[39;49mprocess(imgRGB)\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mmulti_hand_landmarks:\n\u001b[1;32m     25\u001b[0m     \u001b[39mfor\u001b[39;00m handlms \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mmulti_hand_landmarks:\n\u001b[1;32m     26\u001b[0m         \u001b[39m# z = max([lm.z for lm in handlms.landmark])\u001b[39;00m\n",
      "File \u001b[0;32m~/sfsu/big_data/p_final/sources/knn_env/lib/python3.10/site-packages/mediapipe/python/solutions/hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[1;32m    133\u001b[0m   \u001b[39m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m         right hand) of the detected hand.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprocess(input_data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m: image})\n",
      "File \u001b[0;32m~/sfsu/big_data/p_final/sources/knn_env/lib/python3.10/site-packages/mediapipe/python/solution_base.py:366\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    362\u001b[0m         stream\u001b[39m=\u001b[39mstream_name,\n\u001b[1;32m    363\u001b[0m         packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    364\u001b[0m                                  data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 366\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49mwait_until_idle()\n\u001b[1;32m    367\u001b[0m \u001b[39m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m# output stream names.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m solution_outputs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\n\u001b[1;32m    370\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSolutionOutputs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_stream_type_info\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "pTime = time.time()\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    if (success):\n",
    "\n",
    "        cropped_image = crop_img(img)\n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        cv2.putText(cropped_image, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 255), 3) \n",
    "        cv2.imshow(\"image\", cropped_image)\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c39c2c58bc404af50d2976e10c42742003b5dbac9e344f55f3bdf86981ccac4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
